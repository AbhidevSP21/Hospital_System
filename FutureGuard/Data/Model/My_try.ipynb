{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Disease   abdominal_pain   abnormal_menstruation   acidity  \\\n",
      "0  Fungal infection            False                   False     False   \n",
      "1  Fungal infection            False                   False     False   \n",
      "2  Fungal infection            False                   False     False   \n",
      "3  Fungal infection            False                   False     False   \n",
      "4  Fungal infection            False                   False     False   \n",
      "\n",
      "    acute_liver_failure   altered_sensorium   anxiety   back_pain  \\\n",
      "0                 False               False     False       False   \n",
      "1                 False               False     False       False   \n",
      "2                 False               False     False       False   \n",
      "3                 False               False     False       False   \n",
      "4                 False               False     False       False   \n",
      "\n",
      "    belly_pain   blackheads  ...   watering_from_eyes   weakness_in_limbs  \\\n",
      "0        False        False  ...                False               False   \n",
      "1        False        False  ...                False               False   \n",
      "2        False        False  ...                False               False   \n",
      "3        False        False  ...                False               False   \n",
      "4        False        False  ...                False               False   \n",
      "\n",
      "    weakness_of_one_body_side   weight_gain   weight_loss   yellow_crust_ooze  \\\n",
      "0                       False         False         False               False   \n",
      "1                       False         False         False               False   \n",
      "2                       False         False         False               False   \n",
      "3                       False         False         False               False   \n",
      "4                       False         False         False               False   \n",
      "\n",
      "    yellow_urine   yellowing_of_eyes   yellowish_skin  itching  \n",
      "0          False               False            False     True  \n",
      "1          False               False            False    False  \n",
      "2          False               False            False     True  \n",
      "3          False               False            False     True  \n",
      "4          False               False            False     True  \n",
      "\n",
      "[5 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('dataset1.csv')\n",
    "# Replace '0' with NaN to properly handle missing data\n",
    "data.replace('0', pd.NA, inplace=True)\n",
    "\n",
    "# Concatenate the symptom columns into one DataFrame\n",
    "symptom_columns = [f'Symptom_{i}' for i in range(1, 18)]\n",
    "symptom_data = data[symptom_columns]\n",
    "\n",
    "# One-hot encode the symptoms\n",
    "one_hot_encoded_data = pd.get_dummies(symptom_data.stack(), prefix='', prefix_sep='').groupby(level=0).max()\n",
    "\n",
    "# Combine the one-hot encoded symptoms with the original 'Disease' column\n",
    "final_data = pd.concat([data['Disease'], one_hot_encoded_data], axis=1)\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Disease', ' abdominal_pain', ' abnormal_menstruation', ' acidity',\n",
       "       ' acute_liver_failure', ' altered_sensorium', ' anxiety', ' back_pain',\n",
       "       ' belly_pain', ' blackheads',\n",
       "       ...\n",
       "       ' watering_from_eyes', ' weakness_in_limbs',\n",
       "       ' weakness_of_one_body_side', ' weight_gain', ' weight_loss',\n",
       "       ' yellow_crust_ooze', ' yellow_urine', ' yellowing_of_eyes',\n",
       "       ' yellowish_skin', 'itching'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gokul Manoj\\AppData\\Local\\Temp\\ipykernel_5340\\1650043994.py:20: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  test = test.groupby(test.columns, axis=1).agg(np.max)\n",
      "C:\\Users\\Gokul Manoj\\AppData\\Local\\Temp\\ipykernel_5340\\1650043994.py:20: FutureWarning: The provided callable <function max at 0x0000011BC677DA80> is currently using DataFrameGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  test = test.groupby(test.columns, axis=1).agg(np.max)\n",
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.0483 - loss: 3.7255 - val_accuracy: 0.2384 - val_loss: 3.3908\n",
      "Epoch 2/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1272 - loss: 3.3391 - val_accuracy: 0.5194 - val_loss: 2.7909\n",
      "Epoch 3/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1865 - loss: 2.9723 - val_accuracy: 0.7306 - val_loss: 2.2773\n",
      "Epoch 4/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2710 - loss: 2.6034 - val_accuracy: 0.8798 - val_loss: 1.8615\n",
      "Epoch 5/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2833 - loss: 2.4770 - val_accuracy: 0.9244 - val_loss: 1.5901\n",
      "Epoch 6/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3678 - loss: 2.2456 - val_accuracy: 0.9244 - val_loss: 1.3571\n",
      "Epoch 7/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3463 - loss: 2.1546 - val_accuracy: 0.9244 - val_loss: 1.2147\n",
      "Epoch 8/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3757 - loss: 2.0719 - val_accuracy: 0.9244 - val_loss: 1.0982\n",
      "Epoch 9/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4121 - loss: 2.0131 - val_accuracy: 0.9244 - val_loss: 1.0176\n",
      "Epoch 10/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4173 - loss: 1.9476 - val_accuracy: 0.9729 - val_loss: 0.9294\n",
      "Epoch 11/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4043 - loss: 1.9309 - val_accuracy: 0.9729 - val_loss: 0.8775\n",
      "Epoch 12/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4428 - loss: 1.9155 - val_accuracy: 0.9671 - val_loss: 0.8294\n",
      "Epoch 13/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4459 - loss: 1.8177 - val_accuracy: 0.9690 - val_loss: 0.7826\n",
      "Epoch 14/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4552 - loss: 1.7961 - val_accuracy: 0.9690 - val_loss: 0.7340\n",
      "Epoch 15/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4570 - loss: 1.8154 - val_accuracy: 0.9729 - val_loss: 0.7118\n",
      "Epoch 16/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4331 - loss: 1.8497 - val_accuracy: 0.9690 - val_loss: 0.7138\n",
      "Epoch 17/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4717 - loss: 1.7633 - val_accuracy: 0.9729 - val_loss: 0.6653\n",
      "Epoch 18/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4788 - loss: 1.7731 - val_accuracy: 0.9729 - val_loss: 0.6520\n",
      "Epoch 19/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4795 - loss: 1.7341 - val_accuracy: 0.9729 - val_loss: 0.6359\n",
      "Epoch 20/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4724 - loss: 1.7359 - val_accuracy: 0.9729 - val_loss: 0.6206\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9856 - loss: 0.5682 \n",
      "MLP Accuracy: 0.9819168448448181\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import gzip\n",
    "\n",
    "\n",
    "# Machine learning model: XGBoost \n",
    "\n",
    "# import the dataset\n",
    "dataset_df = pd.read_csv('dataset1.csv')\n",
    "\n",
    "# Preprocess\n",
    "dataset_df = dataset_df.apply(lambda col: col.str.strip())\n",
    "\n",
    "test = pd.get_dummies(dataset_df.filter(regex='Symptom'), prefix='', prefix_sep='')\n",
    "test = test.groupby(test.columns, axis=1).agg(np.max)\n",
    "clean_df = pd.merge(test,dataset_df['Disease'], left_index=True, right_index=True)\n",
    "\n",
    "clean_df.to_csv('clean_dataset.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Preprocessing\n",
    "X_data = clean_df.iloc[:,:-1]\n",
    "y_data = clean_df.iloc[:,-1]\n",
    "\n",
    "# Convert y to categorical values\n",
    "y_data = y_data.astype('category')\n",
    "\n",
    "# Convert y categories tu numbers with encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3)\n",
    "\n",
    "# Convert labels to numbers\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Init classifier\n",
    "# model = xgb.XGBClassifier(use_label_encoder=False, reg_alpha=20, reg_lambda=0, eval_metric='mlogloss')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_enc = to_categorical(y_train)\n",
    "y_test_enc = to_categorical(y_test)\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001))),\n",
    "model.add(Dropout(0.5)),\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001))),\n",
    "model.add(Dropout(0.5)),\n",
    "model.add(Dense(y_train_enc.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_enc, epochs=20, batch_size=20, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test_enc)\n",
    "print(f\"MLP Accuracy: {accuracy}\")\n",
    "\n",
    "# Predict\n",
    "preds = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Predicted Disease: [0.00535808 0.00554972 0.00585217 0.01073302 0.00579366 0.00578833\n",
      " 0.01580361 0.0088888  0.01232117 0.01693414 0.00281377 0.01188658\n",
      " 0.03254469 0.00787353 0.02029233 0.0284342  0.01069858 0.0131532\n",
      " 0.13548645 0.03148556 0.0144024  0.02526121 0.01782215 0.02838495\n",
      " 0.06712464 0.04725146 0.01071616 0.04107678 0.11227002 0.00960565\n",
      " 0.01163432 0.04048258 0.03517056 0.0105496  0.02473863 0.00398487\n",
      " 0.0432893  0.0032376  0.00441751 0.04786875 0.01301927]\n"
     ]
    }
   ],
   "source": [
    "true_symptoms = [\"weight_loss\", \"coma\",\"chest_pain\"]  # List the symptoms that are true\n",
    "\n",
    "# Create an array for the test case\n",
    "test_case = np.zeros(X_data.shape[1])  # Initialize all symptoms to False (0)\n",
    "for symptom in true_symptoms:\n",
    "    test_case[X_data.columns.get_loc(symptom)] = 1  # Set True (1) for specified symptoms\n",
    "\n",
    "# Reshape for prediction\n",
    "test_case = test_case.reshape(1, -1)\n",
    "\n",
    "# Predict the disease\n",
    "predicted_disease_prob= model.predict(test_case)\n",
    "\n",
    "print(\"Predicted Disease:\", predicted_disease_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Disease: Heart attack\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get the index of the highest probability\n",
    "disease_index = np.argmax(predicted_disease_prob)\n",
    "\n",
    "# Step 2: Decode the prediction to get the disease name\n",
    "predicted_disease = le.inverse_transform([disease_index])\n",
    "\n",
    "print(\"Predicted Disease:\", predicted_disease[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Disease: Heart attack. Please consult the doctor for further checkup.\n"
     ]
    }
   ],
   "source": [
    "# Threshold for classification\n",
    "threshold = 0.1\n",
    "\n",
    "# Check if the predicted probability is above the threshold\n",
    "predicted_probabilities = predicted_disease_prob # From the prediction you obtained earlier\n",
    "max_probability = np.max(predicted_probabilities)\n",
    "predicted_disease_index = np.argmax(predicted_probabilities)\n",
    "\n",
    "if max_probability >= threshold:\n",
    "    # predicted_disease = le.inverse_transform([predicted_disease_index])\n",
    "    print(f\"Predicted Disease: {predicted_disease[0]}. Please consult the doctor for further checkup.\")\n",
    "else:\n",
    "    print(\"Prediction is uncertain; confidence is below the threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['le.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# joblib.dump(model,\"prediction.joblib\")\n",
    "model.save(\"prediction.h5\")  # Save the entire model in HDF5 format\n",
    "\n",
    "joblib.dump(le,\"le.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
